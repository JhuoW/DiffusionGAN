{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import config\n",
    "import logging\n",
    "import generator_dif\n",
    "import discriminator_dif\n",
    "import copy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DiffusionGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionGAN(object):\n",
    "    def __init__(self):\n",
    "        self.emb_dim = 50\n",
    "        self.train_data = config.small_train_cascades\n",
    "        self.test_data = config.small_test_cascades\n",
    "        self.epoch = 20\n",
    "        self._u2idx = {}\n",
    "        self._idx2u = []\n",
    "        self._buildIndex()  \n",
    "        self._train_cascades = self._readFromFile(self.train_data)  \n",
    "        self._test_cascades = self._readFromFile(self.test_data)\n",
    "        self.train_size = len(self._train_cascades)  # 3419\n",
    "        self.test_size = len(self._test_cascades)\n",
    "        \n",
    "        logging.info(\n",
    "            \"training set size:%d    testing set size:%d\" % (self.train_size, self.test_size))\n",
    "        self.emb_user = np.random.rand(self.user_size, self.emb_dim)\n",
    "        \n",
    "        self.matrix = []\n",
    "        \n",
    "        self.build_generator()\n",
    "        self.build_discriminator()\n",
    "\n",
    "        self.latest_checkpoint = tf.train.latest_checkpoint(config.model_log)\n",
    "        self.saver = tf.train.Saver()\n",
    "        self.config = tf.ConfigProto()\n",
    "        self.config.gpu_options.allow_growth = True\n",
    "        self.init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "        self.sess = tf.Session(config=self.config)\n",
    "        self.sess.run(self.init_op)\n",
    "\n",
    "    def _buildIndex(self):\n",
    "        train_user_set = set()\n",
    "        test_user_set = set()\n",
    "\n",
    "        for line in open(self.train_data):\n",
    "            if len(line.strip()) == 0:\n",
    "                continue\n",
    "            chunks = line.strip().split()\n",
    "            for chunk in chunks:\n",
    "                user, timestamp = chunk.split(',')\n",
    "                train_user_set.add(user)  \n",
    "        for line in open(self.test_data):\n",
    "            if len(line.strip()) == 0:\n",
    "                continue\n",
    "            chunks = line.strip().split()\n",
    "            for chunk in chunks:\n",
    "                user, timestamp = chunk.split(',')\n",
    "                test_user_set.add(user)\n",
    "\n",
    "        pos = 0\n",
    "        for user in train_user_set:\n",
    "            self._u2idx[user] = pos\n",
    "            pos += 1\n",
    "            self._idx2u.append(user)\n",
    "        self.user_size = len(train_user_set)  \n",
    "        logging.info(\"user size : %d\" % self.user_size)\n",
    "\n",
    "    def _readFromFile(self, filename):\n",
    "        t_cascades = []\n",
    "        for line in open(filename):\n",
    "            if len(line.strip()) == 0:\n",
    "                continue\n",
    "            userlist = []\n",
    "            chunks = line.strip().split()\n",
    "            for chunk in chunks:\n",
    "                user, timestamp = chunk.split(',')\n",
    "                if user in self._u2idx:\n",
    "                    userlist.append(self._u2idx[user])\n",
    "\n",
    "            if len(userlist) > 1:\n",
    "                t_cascades.append(userlist)\n",
    "\n",
    "        return t_cascades\n",
    "\n",
    "    def build_generator(self):\n",
    "        self.generator = generator_dif.Generator(node_emd_init=self.emb_user)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "        self.discriminator = discriminator_dif.Discriminator(node_emd_init=self.emb_user)\n",
    "\n",
    "    def write_embeddings_to_file(self):\n",
    "        modes = [self.generator, self.discriminator]\n",
    "        for i in range(2):\n",
    "            embedding_matrix = self.sess.run(modes[i].embedding_matrix)\n",
    "            index = np.array(range(self.user_size)).reshape(-1, 1)\n",
    "            embedding_matrix = np.hstack([index, embedding_matrix])\n",
    "            embedding_list = embedding_matrix.tolist()\n",
    "            embedding_str = [str(int(emb[0])) + \"\\t\" + \"\\t\".join([str(x) for x in emb[1:]]) + \"\\n\"\n",
    "                             for emb in embedding_list]\n",
    "            with open(config.emb_filenames[i], \"w+\") as f:\n",
    "                lines = [str(self.user_size) + \"\\t\" + str(config.n_emb) + \"\\n\"] + embedding_str\n",
    "                f.writelines(lines)\n",
    "                \n",
    "    def write_embeddings_to_file2(self):\n",
    "        modes = [self.generator, self.discriminator]\n",
    "        for i in range(2):\n",
    "            embedding_matrix = self.sess.run(modes[i].embedding_matrix)\n",
    "            self.matrix.append(embedding_matrix)\n",
    "            index = np.array(range(self.user_size)).reshape(-1, 1)\n",
    "            embedding_matrix = np.hstack([index, embedding_matrix])\n",
    "            embedding_list = embedding_matrix.tolist()\n",
    "            embedding_str = [str(int(emb[0])) + \"\\t\" + \"\\t\".join([str(x) for x in emb[1:]]) + \"\\n\"\n",
    "                             for emb in embedding_list]\n",
    "            with open(config.emb_filenames[i], \"w+\") as f:\n",
    "                lines = [str(self.user_size) + \"\\t\" + str(config.n_emb) + \"\\n\"] + embedding_str\n",
    "                f.writelines(lines)\n",
    "\n",
    "    def prepare_data_for_d(self, all_score, U):\n",
    "        copy_score = copy.deepcopy(all_score)  \n",
    "        U_score = copy_score[U]\n",
    "        max_score_id = dict()\n",
    "        for score in U_score:\n",
    "            for i in U:\n",
    "                score[i] = 0\n",
    "            maxid = np.argmax(score)\n",
    "            max_score_id[maxid] = np.max(score)\n",
    "        neg = max(max_score_id, key=max_score_id.get)\n",
    "        return neg\n",
    "\n",
    "    def prepare_data_for_g(self, all_score, U):\n",
    "        copy_score = copy.deepcopy(all_score) \n",
    "        U_score = copy_score[U]\n",
    "        max_score_id = dict()\n",
    "        for score in U_score:\n",
    "            for i in U:\n",
    "                score[i] = 0\n",
    "            maxid = np.argmax(score)\n",
    "            max_score_id[maxid] = np.max(score)\n",
    "        neg = max(max_score_id, key=max_score_id.get)\n",
    "        score = self.computePv_dis2(neg, U)\n",
    "        reward = self.sess.run(self.discriminator.reward,\n",
    "                               feed_dict={self.discriminator.u_t: [neg],\n",
    "                                          self.discriminator.U: U,\n",
    "                                          self.discriminator.score: [score]})\n",
    "        return neg, reward\n",
    "\n",
    "    def computePv_dis(self, u_t, U):\n",
    "        pv = 1.0\n",
    "        feed_dict = {self.discriminator.u_t: u_t, self.discriminator.U: U}\n",
    "        u_t_embedding, U_embedding = self.sess.run([self.discriminator.u_t_embedding, self.discriminator.U_embedding],\n",
    "                                                   feed_dict=feed_dict)\n",
    "        for u in U_embedding:\n",
    "            p_uv = 1. / np.sqrt(np.sum(np.square(u_t_embedding - u)))\n",
    "            pv = pv * (1 - p_uv)\n",
    "        p_v = 1 - pv\n",
    "        return p_v\n",
    "\n",
    "    def computePv_dis2(self, u_t, U):\n",
    "        pv = 1.0\n",
    "        feed_dict = {self.discriminator.u_t:[u_t], self.discriminator.U: U}\n",
    "        u_t_embedding, U_embedding = self.sess.run([self.discriminator.u_t_embedding, self.discriminator.U_embedding],\n",
    "                                                   feed_dict=feed_dict)\n",
    "        for u in U_embedding:\n",
    "            p_uv = 1. / np.sqrt(np.sum(np.square(u_t_embedding - u)))\n",
    "            pv = pv * (1 - p_uv)\n",
    "        p_v = 1 - pv\n",
    "        return p_v\n",
    "\n",
    "    def computePv_gen(self, u_t, U):\n",
    "        pv = 1.0\n",
    "        feed_dict = {self.generator.u_t: [u_t], self.generator.U: U}\n",
    "        u_t_embedding, U_embedding = self.sess.run([self.generator.u_t_embedding, self.generator.U_embedding],\n",
    "                                                   feed_dict=feed_dict)\n",
    "        for u in U_embedding:\n",
    "            p_uv = 1. / np.sqrt(np.sum(np.square(u_t_embedding - u)))\n",
    "            pv = pv * (1 - p_uv)\n",
    "        p_v = 1 - pv\n",
    "        return p_v\n",
    "\n",
    "    def all_score(self):\n",
    "        embedding_matrix = self.sess.run(self.generator.embedding_matrix)\n",
    "        all_score = np.matmul(embedding_matrix,embedding_matrix.transpose())\n",
    "        for i in range(self.user_size):\n",
    "            all_score[i][i] = 0\n",
    "        return all_score\n",
    "\n",
    "    def train(self):\n",
    "        checkpoint = tf.train.get_checkpoint_state(config.model_log)\n",
    "        if checkpoint and checkpoint.model_checkpoint_path and config.load_model:\n",
    "            print(\"loading the checkpoint: %s\" % checkpoint.model_checkpoint_path)\n",
    "            self.saver.restore(self.sess, checkpoint.model_checkpoint_path)\n",
    "\n",
    "        self.write_embeddings_to_file()\n",
    "        print(\"start training...\")\n",
    "        for epoch in range(config.n_epochs):\n",
    "            print(\"epoch %d\" % epoch)\n",
    "            if epoch > 0 and epoch % config.save_steps == 0:\n",
    "                self.saver.save(self.sess, config.model_log + \"model.checkpoint\")\n",
    "            for d_epoch in range(config.n_epochs_dis):\n",
    "                for cascade in self._train_cascades:\n",
    "                    all_score = self.all_score()\n",
    "                    for i in range(1, len(cascade)):\n",
    "                        U = cascade[0:i]\n",
    "                        neg = self.prepare_data_for_d(all_score, U)\n",
    "                        u_true = cascade[i]\n",
    "                        labels = [0, 1]\n",
    "                        u = [neg, u_true]\n",
    "                        score = self.computePv_dis(u, U)\n",
    "                        self.sess.run(self.discriminator.d_updates, feed_dict={self.discriminator.u_t: u,\n",
    "                                                                               self.discriminator.U: U,\n",
    "                                                                               self.discriminator.label: labels,\n",
    "                                                                               self.discriminator.score: [score]})\n",
    "            for g_epoch in range(config.n_epochs_gen):\n",
    "                for cascade in self._train_cascades:\n",
    "                    all_score = self.all_score()\n",
    "                    for i in range(1, len(cascade)):\n",
    "                        U = cascade[0:i]\n",
    "                        neg, reward = self.prepare_data_for_g(all_score, U)\n",
    "                        p_v = self.computePv_gen(neg, U)\n",
    "                        self.sess.run(self.generator.g_updates, feed_dict={self.generator.u_t: [neg],\n",
    "                                                                           self.generator.U: U,\n",
    "                                                                           self.generator.reward: reward,\n",
    "                                                                           self.generator.p_v: [p_v]})\n",
    "\n",
    "        self.write_embeddings_to_file2()\n",
    "        print(\"training completes\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion_gan = DiffusionGAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2u = diffusion_gan._idx2u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion_gan.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = diffusion_gan.matrix\n",
    "emb_gen = matrix[0]\n",
    "emb_dis = matrix[1]\n",
    "user_emb = emb_dis\n",
    "user_size = diffusion_gan.user_size\n",
    "test_size = diffusion_gan.test_size\n",
    "print(emb_gen)\n",
    "print(emb_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
